{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook explains how to uncover risks related to your usecase based on a given taxonomy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\n",
    "#     \"Incident ID\",\n",
    "#     \"Annotation Status\",\n",
    "#     \"Physical Objects\",\n",
    "#     \"Entertainment Industry\",\n",
    "#     \"Report, Test, or Study of data\",\n",
    "#     \"Deployed\",\n",
    "#     \"Producer Test in Controlled Conditions\",\n",
    "#     \"Producer Test in Operational Conditions\",\n",
    "#     \"User Test in Controlled Conditions\",\n",
    "#     \"User Test in Operational Conditions\",\n",
    "#     \"Harm Domain\",\n",
    "#     \"AI System\",\n",
    "#     \"Clear link to technology\",\n",
    "#     \"There is a potentially identifiable specific entity that experienced the harm\",\n",
    "#     \"AI Harm Level\",\n",
    "#     \"Entities\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\n",
    "#     \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1.csv\"\n",
    "# )[columns]\n",
    "\n",
    "# df = df[~df[\"AI Harm Level\"].isin([\"none\", \"unclear\"])]\n",
    "# # df = df[\n",
    "# #     df[\"Annotation Status\"].isin([\"4. Peer review complete\", \"6. Complete and final\"])\n",
    "# # ]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(\n",
    "#     df,\n",
    "#     pd.read_csv(\n",
    "#         \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv0.csv\"\n",
    "#     ),\n",
    "#     on=\"Incident ID\",\n",
    "#     how=\"inner\",\n",
    "# )[\n",
    "#     [\n",
    "#         \"Incident ID\",\n",
    "#         \"Short Description\",\n",
    "#         \"Full Description\",\n",
    "#         \"Physical Objects\",\n",
    "#         \"Entertainment Industry\",\n",
    "#         \"Report, Test, or Study of data\",\n",
    "#         \"Deployed\",\n",
    "#         \"Producer Test in Controlled Conditions\",\n",
    "#         \"Producer Test in Operational Conditions\",\n",
    "#         \"User Test in Controlled Conditions\",\n",
    "#         \"User Test in Operational Conditions\",\n",
    "#         \"Harm Domain\",\n",
    "#         \"AI System\",\n",
    "#         \"Clear link to technology\",\n",
    "#         \"There is a potentially identifiable specific entity that experienced the harm\",\n",
    "#         \"AI Harm Level\",\n",
    "#         \"Harm Type\",\n",
    "#         \"Entities\",\n",
    "#     ]\n",
    "# ].sort_values(\n",
    "#     [\"Incident ID\"]\n",
    "# ).reset_index(\n",
    "#     drop=True\n",
    "# ).dropna().to_csv(\n",
    "#     \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1_Annotator-all_with_harm_type.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(\n",
    "#     [\n",
    "#         pd.read_csv(\n",
    "#             \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1_Annotator-1.csv\"\n",
    "#         ),\n",
    "#         pd.read_csv(\n",
    "#             \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1_Annotator-2.csv\"\n",
    "#         ),\n",
    "#         pd.read_csv(\n",
    "#             \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1_Annotator-3.csv\"\n",
    "#         ),\n",
    "#     ],\n",
    "#     keys=[\"Incident ID\"],\n",
    "# )[columns]\n",
    "\n",
    "# # df = df[~df[\"AI Harm Level\"].isin([\"none\", \"unclear\"])]\n",
    "# # df = df[~df[\"Annotation Status\"].isin([\"1. Annotation in progress\"])]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = (\n",
    "#     pd.merge(\n",
    "#         df,\n",
    "#         pd.read_csv(\n",
    "#             \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv0.csv\"\n",
    "#         ),\n",
    "#         on=\"Incident ID\",\n",
    "#         how=\"inner\",\n",
    "#     )[\n",
    "#         [\n",
    "#             \"Incident ID\",\n",
    "#             \"Short Description\",\n",
    "#             \"Full Description\",\n",
    "#             \"Annotation Status_x\",\n",
    "#             \"Physical Objects\",\n",
    "#             \"Entertainment Industry\",\n",
    "#             \"Report, Test, or Study of data\",\n",
    "#             \"Deployed\",\n",
    "#             \"Producer Test in Controlled Conditions\",\n",
    "#             \"Producer Test in Operational Conditions\",\n",
    "#             \"User Test in Controlled Conditions\",\n",
    "#             \"User Test in Operational Conditions\",\n",
    "#             \"Harm Domain\",\n",
    "#             \"AI System\",\n",
    "#             \"Clear link to technology\",\n",
    "#             \"There is a potentially identifiable specific entity that experienced the harm\",\n",
    "#             \"AI Harm Level\",\n",
    "#             \"Harm Type\",\n",
    "#             \"Entities\",\n",
    "#         ]\n",
    "#     ]\n",
    "#     .sort_values([\"Incident ID\"])\n",
    "#     .reset_index(drop=True)\n",
    "#     # .dropna(subset=[\"Harm Type\"])\n",
    "# )\n",
    "# df.shape\n",
    "\n",
    "# # df.to_csv(\n",
    "# #     \"/Users/dhaval/Downloads/mongodump_full_snapshot/classifications_CSETv1_Annotator-all_with_harm_type.csv\",\n",
    "# #     index=False,\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhaval/Projects/Usage-Governance/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/dhaval/.pyenv/versions/nexus/lib/python3.12/site-packages/tika/__init__.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__('pkg_resources').declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from risk_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/risk-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-15 08:37:13:277] - INFO - RiskAtlasNexus - Created RITS inference engine.\n"
     ]
    }
   ],
   "source": [
    "# inference_engine = OllamaInferenceEngine(\n",
    "#     model_name_or_path=\"granite3.2:8b\",\n",
    "#     credentials=InferenceEngineCredentials(api_url=\"OLLAMA_API_URL\"),\n",
    "#     parameters=OllamaInferenceEngineParams(\n",
    "#         num_predict=1000, num_ctx=8192, temperature=0, repeat_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )\n",
    "\n",
    "inference_engine = RITSInferenceEngine(\n",
    "    model_name_or_path=\"meta-llama/llama-3-3-70b-instruct\",\n",
    "    credentials={\n",
    "        \"api_key\": \"cbc683b3a1a7c52d2a73008b785d2811\",\n",
    "        \"api_url\": \"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com\",\n",
    "    },\n",
    "    parameters=RITSInferenceEngineParams(max_completion_tokens=1000, temperature=0.7),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of RiskAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `RiskAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-15 08:37:13:390] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification API\n",
    "\n",
    "RiskAtlasNexus.identify_risks_from_usecases()\n",
    "\n",
    "Params:\n",
    "\n",
    "- usecases (List[str]):\n",
    "  A List of strings describing AI usecases\n",
    "- inference_engine (InferenceEngine):\n",
    "  An LLM inference engine to infer risks from the usecases.\n",
    "- taxonomy (str, optional):\n",
    "  The string label for a taxonomy. Default to None.\n",
    "- cot_examples (Dict[str, List], optional):\n",
    "  The Chain of Thought (CoT) examples to use in the risk identification.\n",
    "  The example template is available at src/risk_atlas_nexus/data/templates/risk_generation_cot.json.\n",
    "  Assign the ID of the taxonomy you wish to use as the key for CoT examples. Providing this value\n",
    "  will override the CoT examples present in the template master. Default to None.\n",
    "- max_risk (int, optional):\n",
    "  The maximum number of risks to extract. Pass None to allow the inference engine to determine the number of risks. Defaults to None.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using dataset \n",
    "- data prepared from classifications_CSETv1.csv annontation file, \n",
    "- excluding AI Harm level = [\"none\", \"unclear\"]\n",
    "- considering all annontation statuses.\n",
    "- Only taking into account tangible AI harm (event, near-miss, issue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On March 18, 2018, an Uber autonomous vehicle struck and killed 49 year-old Elaine Herzberg during testing in Tempe, Arizona. Herzberg was walking her bicycle outside a crosswalk around 10:00pm when the vehicle hit her at a speed of 39-44 miles per hour. The vehicle, a Volvo XC90 equipped with cameras, radar, and LIDAR, was operating in autonomous mode with Rafaela Vasquez, 44, in the driver’s seat as a safety monitor. Internal video from the vehicle indicates that Vasquez was watching television on their phone prior to the collision, only looking up to the street 0.5 seconds before impact. Vasquez has been charged with manslaughter in the incident.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"classifications_CSETv1_Annotator-all_with_harm_type.csv\")\n",
    "df[\"Full Description\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Identification using IBM AI Risk taxonomy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with RITS: 100%|██████████| 11/11 [00:29<00:00,  2.70s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:29<00:00,  2.67s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:31<00:00,  2.90s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:04<00:00,  4.63s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [01:01<00:00,  5.58s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:37<00:00,  3.45s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:05<00:00,  5.12s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:44<00:00,  4.09s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:39<00:00,  3.60s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:05<00:00,  5.56s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:33<00:00,  3.06s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:05<00:00,  5.08s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:37<00:00,  3.39s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:39<00:00,  3.59s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:07<00:00,  7.73s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:31<00:00,  2.84s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:29<00:00,  2.69s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:04<00:00,  4.59s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:50<00:00,  4.62s/it]\n",
      "Inferring with RITS: 100%|██████████| 11/11 [00:41<00:00,  3.74s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:06<00:00,  6.36s/it]\n",
      "Inferring with RITS: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextGenerationInferenceOutput(prediction={'harm': ['Physical health/safety', 'Infrastructure'], 'explanation': \"The incident resulted in the death of Elaine Herzberg, which falls under the 'Physical health/safety' category. Additionally, the fact that the accident occurred on a road, which is part of the infrastructure, and involved a vehicle, also suggests a potential harm to the infrastructure category, as the normal functioning of the road and transportation system was impacted.\"}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='meta-llama/llama-3-3-70b-instruct', inference_engine='RITS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risks = risk_atlas_nexus.identify_risks_from_usecases(\n",
    "    usecases=list(df[\"Full Description\"]),\n",
    "    inference_engine=inference_engine\n",
    ")\n",
    "\n",
    "risks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
