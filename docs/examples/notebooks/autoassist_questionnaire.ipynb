{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-fill Questionnaire using Chain of Thought or Few-Shot Examples\n",
    "\n",
    "This notebook showcases the application of few-shot examples in autofilling questionnaires. It utilizes a json file (`risk_questionnaire_cot.json`) to\n",
    "provide the LLM with example responses for some use-cases.\n",
    "\n",
    "By leveraging these few-shot examples, we can enable seamless completion of lengthy questionnaires, minimizing manual effort and improving overall efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhaval/Projects/Usage-Governance/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/dhaval/.pyenv/versions/nexus/lib/python3.12/site-packages/tika/__init__.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__('pkg_resources').declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from risk_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "\n",
    "from risk_atlas_nexus.data import load_resource\n",
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/risk-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-20 11:27:02:130] - INFO - RiskAtlasNexus - Created RITS inference engine.\n"
     ]
    }
   ],
   "source": [
    "# inference_engine = OllamaInferenceEngine(\n",
    "#     model_name_or_path=\"granite3.2:8b\",\n",
    "#     credentials=InferenceEngineCredentials(api_url=\"http://localhost:11434\"),\n",
    "#     parameters=OllamaInferenceEngineParams(\n",
    "#         num_predict=1000, temperature=0, repeat_penalty=1, num_ctx=8192\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )\n",
    "\n",
    "inference_engine = RITSInferenceEngine(\n",
    "    model_name_or_path=\"ibm-granite/granite-3.3-8b-instruct\",\n",
    "    credentials={\n",
    "        \"api_key\": \"cbc683b3a1a7c52d2a73008b785d2811\",\n",
    "        \"api_url\": \"https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com\",\n",
    "    },\n",
    "    parameters=RITSInferenceEngineParams(max_completion_tokens=1000, temperature=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of RiskAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `RiskAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-20 11:27:02:248] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Examples for Auto-Assist Functionality\n",
    "\n",
    "The auto-assist feature utilizes few-shot examples defined in the file `risk_atlas_nexus/data/templates/risk_questionnaire_cot.json` to predict the output of the risk questionnaire.\n",
    "\n",
    "**Customization:**\n",
    "\n",
    "To adapt this auto-assist functionality to custom risk questionnaire, users need to provide their own set of questions, example intents, and corresponding answers in a json file such as in [risk_questionnaire_cot.json](https://github.com/IBM/risk-atlas-nexus/blob/main/src/risk_atlas_nexus/data/templates/risk_questionnaire_cot.json). This will enable the LLM to learn from these few-shot examples and generate responses for unseen queries.\n",
    "\n",
    "**CoT Template - Zero Shot method**\n",
    "\n",
    "Each question is accompanied by corresponding examples provided as an empty list.\n",
    "\n",
    "```shell\n",
    "  [\n",
    "      {\n",
    "          \"question\": \"In which environment is the system used?\",\n",
    "          \"cot_examples\": []\n",
    "      }\n",
    "      ...\n",
    "  ]\n",
    "```\n",
    "\n",
    "**CoT Template - Few Shot method**\n",
    "\n",
    "Each question is associated with a list of examples, each containing intent, answer, and optional explanation.\n",
    "\n",
    "```shell\n",
    "  [\n",
    "      {\n",
    "          \"question\": \"In which environment is the system used?\",\n",
    "          \"cot_examples\": [\n",
    "            {\n",
    "              \"intent\": \"Find patterns in healthcare insurance claims\",\n",
    "              \"answer\": \"Insurance Claims Processing or Risk Management or Data Analytics\",\n",
    "              \"explanation\": \"The system might be used by an insurance company's claims processing department to analyze and identify patterns in healthcare insurance claims.\"\n",
    "            },\n",
    "            {\n",
    "                \"intent\": \"optimize supply chain management in Investment banks\",\n",
    "                \"answer\": \"Treasury Departments or Asset Management Divisions or Private Banking Units\",\n",
    "                \"explanation\": null\n",
    "            },\n",
    "            ...\n",
    "          ],\n",
    "          \"response_format\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"answer\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\n",
    "                        \"Yes\",\n",
    "                        \"No\",\n",
    "                        \"Maybe\"\n",
    "                    ]\n",
    "                },\n",
    "                \"explanation\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"answer\",\n",
    "                \"explanation\"\n",
    "            ]\n",
    "        }\n",
    "      }\n",
    "      ...\n",
    "  ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Risk Questionnaire\n",
    "\n",
    "**Note:** The cell below loads examples of risk questionnaires from Risk Atlas Master. To load your custom questionnaire, create it according to the specified format and load it instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 'Q1',\n",
       " 'question': \"Did the incident occur in a domain with physical objects? 'Yes' if the AI system(s) is embedded in hardware that can interact, affect, and change with the physical objects (roads, factories, medical facilities, etc.). 'No' if the system cannot. This includes systems that inform, detect, predict, or recommend.\",\n",
       " 'cot_examples': [{'intent': \"Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.\",\n",
       "   'answer': 'No'},\n",
       "  {'intent': 'An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.',\n",
       "   'answer': 'Yes'}],\n",
       " 'response_format': {'type': 'object',\n",
       "  'properties': {'answer': {'type': 'string', 'enum': ['Yes', 'No', 'Maybe']},\n",
       "   'explanation': {'type': 'string'}},\n",
       "  'required': ['answer', 'explanation']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_questionnaire = load_resource(\"cset_ai_harm_questionnaire.json\")\n",
    "\n",
    "risk_questionnaire[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to use the inference engine to get the LLM outputs. `generate_zero_shot_risk_questionnaire_output` which gives the zero-shot output for the question and `generate_few_shot_risk_questionnaire_output` which gives the output using few-shot examples defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with RITS: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: Did the incident occur in a domain with physical objects? 'Yes' if the AI system(s) is embedded in hardware that can interact, affect, and change with the physical objects (roads, factories, medical facilities, etc.). 'No' if the system cannot. This includes systems that inform, detect, predict, or recommend.\n",
      "A: {'answer': 'No', 'explanation': \"The task described involves using AI to draft a government policy report, which is a domain of information and analysis rather than direct interaction with physical objects. The AI system is being used to analyze input documents and understand court rulings on automated penalties in Australia's welfare system. This process does not involve physical interaction with objects like roads, factories, or medical facilities. Instead, it focuses on processing and interpreting data from legal documents.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usecase = \"Using AI to  write a government policy report on automated decision-making in Australia's welfare system. The task will include  drafting a comprehensive section analyzing input documents to understand how Australian federal courts have addressed automated penalties in welfare systems and ensure the output is factually correct.\"\n",
    "\n",
    "results = risk_atlas_nexus.generate_few_shot_risk_questionnaire_output(\n",
    "    usecase,\n",
    "    risk_questionnaire,\n",
    "    inference_engine,\n",
    ")\n",
    "\n",
    "for index, (risk_question, result) in enumerate(\n",
    "    zip(risk_questionnaire, results), start=1\n",
    "):\n",
    "    print(f\"\\n{index}: \" + risk_question[\"question\"] + \"\\nA: \" + str(result.prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
