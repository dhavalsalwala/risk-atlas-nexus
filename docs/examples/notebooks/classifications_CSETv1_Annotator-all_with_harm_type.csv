,Incident ID,Short Description,Full Description,Physical Objects,Entertainment Industry,"Report, Test, or Study of data",Deployed,Producer Test in Controlled Conditions,Producer Test in Operational Conditions,User Test in Controlled Conditions,User Test in Operational Conditions,Harm Domain,AI System,Clear link to technology,There is a potentially identifiable specific entity that experienced the harm,AI Harm Level,Harm Type,Entities
0,4,"An Uber autonomous vehicle in autonomous mode struck and killed a pedestrian in Tempe, Arizona on March 18, 2018.","On March 18, 2018, an Uber autonomous vehicle struck and killed 49 year-old Elaine Herzberg during testing in Tempe, Arizona. Herzberg was walking her bicycle outside a crosswalk around 10:00pm when the vehicle hit her at a speed of 39-44 miles per hour. The vehicle, a Volvo XC90 equipped with cameras, radar, and LIDAR, was operating in autonomous mode with Rafaela Vasquez, 44, in the driver’s seat as a safety monitor. Internal video from the vehicle indicates that Vasquez was watching television on their phone prior to the collision, only looking up to the street 0.5 seconds before impact. Vasquez has been charged with manslaughter in the incident.",yes,no,no,no,no,yes,no,no,yes,yes,yes,True,AI tangible harm event,"physical health/safety, physical property","Uber, Volvo XC90 SUV autonomous vehicle, Elaine Herzberg, Rafaela Vasquez"
1,8,Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.,"Uber's autonomous vehicles have been recorded running red lights on two occasions in a pilot program on the streets of San Francisco, California. A witness, Christoper Koff, reported seeing the AI enabled Volvo XC90 SUV pass through a red light three seconds after the light had turned red and while a pedestrian was in the crosswalk. There were no injuries or collisions. Uber has denied the claim this was the system's error, citing human operator error and suspending the driver. Two Uber employees reported to the New York Times that the fault was of the AI system.",yes,no,no,no,no,yes,no,no,yes,yes,yes,True,AI tangible harm near-miss,"physical health/safety, physical property","Uber, Volvo XC90 SUV, Pedestrian, Charles Rotter"
4,20,Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.,"Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autonomous driving mode was in use. The autonomous vehicle's driving capabilities range from fully human-controlled to fully autonomous, allowing the system to control speed, direction, acceleration, deceleration, and lane changes. In most cases, the driver was given warning prior to impact, alerting the human driver to the need of intervention.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,"physical health/safety, financial loss","Tesla Model X, Tesla, Tesla Model S, Tesla Autopilot, Joshua Brown, Wei \""Walter\"" Huang, 28-year-old Tesla driver, Maria Smith, Massachusetts state police trooper, Nicholas Ciarlone, unnamed Tesla driver (NC), Nash county deputy and trooper, Frank Baressi's trailer, 2010 Mazda 3, 2017 Audi A4, 2010 Mazda 3 driver, 2017 Audi A4 driver, United Fire Authority mechanic truck driver, United Fire Authority truck, Massachusetts state police trooper vehicle, Nash county police vehicles, unnamed Tesla driver (AZ), Ambulance (AZ), Police vehicle (AZ), Police sergeant (AZ), Ambulance occupants (AZ)"
6,22,"Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.","Google-owned directions app Waze sent drivers toward areas impacted by the Skirball wildfires in Los Angeles late December 2017. The app looks at current traffic patterns and suggests routes that avoid major congestion. In the case of mass evacuations, as were implemented for these fires, congestion was seen on the evacuation routes leading the app to direct drivers toward the empty roads. These roads were empty because the area ablaze and impassable. Waze/Google engineers typically work with departments of transportation on traffic pattern changes to augment its directions, however in the case of a quickly-developed emergency, the app did not provide safe driving directions.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm near-miss,physical health/safety,"Waze, Google, Waze, Google Maps, and Apple Maps users, Google Maps, Apple Maps, Apple"
7,23,"A self-driving public shuttle developed by Keolis North America was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada.","A self-driving shuttle in Las Vegas was involved in a collision, with passengers on board, a few hours after its initial release. The Navya Arma model shuttle, developed by company Keolis North America, was backed-into by a human-driven delivery truck. The self-driving shuttle accurately detected the backing up truck and stopped its forward motion, however it did not reverse to avoid collision. The driver of the delivery truck was ticketed.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,"physical health/safety, physical property","self-driving eight-seater electric shuttle, Keolis, Navya, Truck, Shuttle passengers"
8,34,"There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.","There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices. In one case, a 6-year-old girl asked her Alexa Echo Dot to ""play doll house with me and get me a doll house."" The Alexa ordered a $150-170 dollhouse and four pounds of sugar cookies. When news reporters began covering this event, reports surfaced of the news anchor's voices triggering more Amazon Alexa products to order dollhouses. Other instances include a Superbowl advertisement that caused Amazon Alexa's to begin playing whale sounds, turn on/off hall lights, and order cat food delivered to the home.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm near-miss,financial loss,"Brooke Neitzel, Megan Neitzel, Alexa, Amazon, CW6 News anchor, CW6 News viewers with Alexas"
9,36,Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker,"In November 2018, Dong Mingzhu, the chairwoman of China's biggest maker of air conditioners, Gree Electric Appliances, had her face displayed on a huge screen erected along a street in the port city of Ningbo that displays images of people caught jaywalking by surveillance cameras. The artificial software used by the traffic police erred in capturing Dong's image from an advertisement on the side of a moving bus.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm near-miss,other tangible harm,"Jaywalking detection algorithm, Dong Mingzhu"
11,40,"Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.","In 2018, researchers at Dartmouth College conducted a study comparing the Correctional Offender Management Profiling for Alternative Sanctions' (COMPAS), a recidivism risk-assessment algorithmic tool, and 462 random untrained human subjects' ability to predict criminals' risk of recidivism. Researchers gave the subjects descriptions of defendents, highlighting seven pieces of information, and asked subjects to rate the risk of a defendant's recidivism from 1-10. The pooled judgment of these untrained subjects' was accurate 67% of the time, compared to COMPAS's accuracy rate of 65%.",no,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,social or political systems,"Black people, Northpointe, ProPublica, Broward County, Glenn Rodríguez, Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), Equivant (formerly Northpointe), Julia Dressel, Hany Farid, Defendants assessed by COMPAS"
14,51,"On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.","On July 7, 2016, a Knightscope K5 autonomous security robot patrolling the Stanford Shopping Center in Palo Alto, CA collided with a 16-month old boy, leaving the boy with a scrape and minor swelling. The Knightscope K5 carries nearly 30 environment sensors including LIDAR, sonar, vibration detectors, and 360-degree HD video cameras.  The company called this a “freakish accident” and apologized to the family.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,physical health/safety,"Knightscope K5 security robot, Knightscope, Stanford Mall, Harwin Cheng"
17,68,"A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.","A robot at an office building in Washington, DC ran itself into a water fountain. The robot, named Knightscope K5, was developed as a security robot that uses facial recognition and a variety of sensors to detect criminals. The reasons the robot fell into the fountain are unclear. ",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,physical property,"Knightscope, Knightscope K5 security robot \""Steve\, Washington Harbour office and retail complex"
18,71,"On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google’s hometown of Mountain View, CA.","On February 14, 2016, a Google autonomous test vehicle was involved in a low-speed collision with a bus in Google’s hometown of Mountain View, CA. The self-driving car, a Lexus RX450h SUV, was attempting to navigate around an obstruction by merging toward the middle of a wide lane on El Camino Real, while a bus was approaching from the rear. The car and its test driver expected that the bus would slow and allow the merge, however the bus continued, apparently not expecting the self-driving car to attempt the merge, resulting in a low-speed collision. In a public statement, Google acknowledged partial fault for the incident and updated their software to assume that large vehicles are less likely to give way.",yes,no,no,yes,no,yes,no,no,yes,yes,yes,True,AI tangible harm event,physical property,"Delphi Technologies, Delphi Audi SQ5, Unnamed car, Google, Google Lexus SUV, Mountain View city bus, Lexus test driver, Google Lexus RX450 SUV, Commercial van, Waymo, Waymo Chrysler Pacifica, Waymo self-driving car human operator, Honda sedan and driver"
23,92,"In November 2019, Apple Card clients claimed that the credit assessment algorithm possesses a gender bias in favor of men.","In November 2019, customers of Goldman-Sachs and Apple's Apple Card, the first credit offering by Goldman-Sachs, claimed that there was gender discrimination in the credit assessment algorithm that distributes credit lines, with men receiving significantly higher credit limits than women with equal credit qualifications. Apple co-founder Steve Wozniak confirmed this also happened with him and his wife and the New York Department for Financial Services have launched an investigation regarding the discrimination claim. In response to this incident, Goldman Sachs made a statement that it has not and will never make decisions based on factors like gender, race, age, sexual orientation or any other legally prohibited factors when determining credit worthiness.",no,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,financial loss,"Goldman Sachs, New York State Department of Financial Services, Apple, Apple Card, Apple Card female users, Apple Card female users"
26,97,"A Tesla Model 3 mis-recognized flags with ""COOP"" written vertically on them as traffic lights.","A Tesla Model 3 driver shared a video of their car's Autopilot system malfunctioning. The screen inside the car shows that Autopilot believes it is facing a traffic light that is alternating between red and yellow, when in fact it is looking at several white flags with the letters ""COOP"" written vertically.",yes,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm issue,other tangible harm,"Reddit user cyntrex, Tesla, Tesla Model 3, Tesla Autopilot"
27,101,"A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.","The system that distributes childcare benefits in the Netherlands was found to have incorrectly accused thousands of families of fraud, based on algorithmic risk assessments. The process of appealing these accusations often also involved algorithms, leaving many families with no recourse. The system took account of factors including whether someone had a second nationality, leaving immigrants and people of color disproportionately affected.",no,no,no,yes,no,no,no,no,yes,yes,yes,True,AI tangible harm event,"financial loss, social or political systems","Dutch Tax Authority, Childcare benefits recipients, Childcare benefits recipients , Fraud prediction algorithm, Dutch Data Protection Authority, Trouw, Childcare benefits recipients"
